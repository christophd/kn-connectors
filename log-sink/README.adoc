= Knative connector log-sink

Knative eventing connector based on https://camel.apache.org/camel-kamelets/[Apache Camel Kamelets].
The connector project creates a container image that is pushed into a registry so the image can be referenced in a Kubernetes deployment.

== Kamelet properties

The kn-connector source images provides these properties that you can set (e.g. via environment properties on the deployment).

.Kamelet properties
include::properties.adoc[]

== Build the container image

The project uses Quarkus in combination with Apache Camel, Kamelets and Maven as a build tool.

You can use the following Maven commands to build the container image.

[source,shell]
----
./mvnw package -Dquarkus.container-image.build=true
----

The container image uses the project version and image group defined in the Maven POM.
You can customize the image group with `-Dquarkus.container-image.group=my-group`.

By default, the container image looks like this:

[source,text]
----
quay.io/openshift-knative/kn-connector-log-sink:1.0-SNAPSHOT
----

The project leverages the Quarkus Kubernetes and container image extensions so you can use Quarkus properties and configurations to customize the resulting container image.

See these extensions for details:
* https://quarkus.io/guides/deploying-to-kubernetes
* https://quarkus.io/guides/container-image

== Push the container image

[source,shell]
----
./mvnw package -Dquarkus.container-image.build=true -Dquarkus.container-image.push=true
----

Pushes the image to the image registry defined in the Maven POM.
The default registry is https://quay.io/[quay.io].

You can customize the registry with `-Dquarkus.container-image.registry=localhost:5001` (e.g. when connecting to local Kind cluster).

In case you want to connect with a local cluster like Kind or Minikube you may also need to set `-Dquarkus.container-image.insecure=true`.

== Kubernetes manifest

The build produces a Kubernetes manifest in (`target/kubernetes/kubernetes.yml`).
This manifest holds all resources required to run the application on your Kubernetes cluster.

You can customize the Kubernetes resources in link:src/main/kubernetes/kubernetes.yml[src/main/kubernetes/kubernetes.yml].
This is being used as a basis and Quarkus will generate the final manifest in `target/kubernetes/kubernetes.yml` during the build.

The final Kubernetes manifest includes:

* Service
* Deployment
* Trigger

== Deploy to Kubernetes

You can deploy the application to Kubernetes with:

[source,shell]
----
./mvnw package -Dquarkus.kubernetes.deploy=true
----

This deploys the application to the current Kubernetes cluster that you are connected to (e.g. via `kubectl config set-context --current` and `kubectl config view --minify`).

You may change the target namespace with `-Dquarkus.kubernetes.namespace=my-namespace`.

[source,shell]
----
./mvnw package -Dquarkus.kubernetes.deploy=true -Dquarkus.kubernetes.namespace=my-namespace
----

== Kamelet sink Pipe

The sink consumes events from the Knative broker.
It uses a Pipe resource as the central piece of code to define how the Knative events are consumed and where the events get forwarted to.

The Pipe is a YAML file located in link:src/main/resources/camel/kn-connector-sink.yaml[src/main/resources/camel/kn-connector-sink.yaml]

.kn-connector-sink.yaml
[source,yaml]
----
apiVersion: camel.apache.org/v1
kind: Pipe
metadata:
  name: kn-connector-log-sink
spec:
  source:
    ref:
      kind: Broker
      apiVersion: eventing.knative.dev/v1
      name: default
    properties:
      type: ""
  sink:
    ref:
      kind: Kamelet
      apiVersion: camel.apache.org/v1
      name: log-sink
----

This connector uses the https://camel.apache.org/camel-kamelets/log-sink.html[log-sink] Kamelet and consumes events from the Knative broker.

The Pipe references a Knative broker as a source and connects to a Kamelet as a sink.

The name of the broker is always `default` because the Knative Trigger resource is responsible for connecting the application to the Knative broker.
The Trigger decides when to call the application as it provides the events to the application based on the trigger configuration.

This way the same container image can be used with different brokers and events (e.g. by adding filter criteria to the Trigger).
It is only a matter of configuring the Trigger resource that connects the application with the Knative broker.

You can find a sample Trigger in link:src/main/kubernetes/kubernetes.yml[src/main/kubernetes/kubernetes.yml]

[source,yaml]
----
apiVersion: eventing.knative.dev/v1
kind: Trigger
metadata:
  annotations:
    eventing.knative.dev/creator: kn-connectors
  labels:
    eventing.knative.dev/connector: log-sink
    eventing.knative.dev/broker: default
  name: kn-connector-log-sink
spec:
  broker: default
  subscriber:
    ref:
      apiVersion: v1
      kind: Service
      name: kn-connector-log-sink
    uri: /events
----

== Configuration

Each Kamelet defines a set of properties.
The user is able to customize these properties when running a connector deployment.

=== Environment variables

You can customize the properties via environment variables on the deployment:

.Environment variables
include::properties.adoc[]

You can set the environment variable on the running deployment:

[source,shell]
----
kubectl set env deployment/kn-connector-log-sink CAMEL_KAMELET_LOG_SINK_MULTILINE=false
----

The environment variables that overwrite properties on the Kamelet sink follow a naming convention:

* CAMEL_KAMELET_{{KAMELET_NAME}}_{{PROPERTY_NAME}}={{PROPERTY_VALUE}}

The name represents the name of the Kamelet sink as defined in the https://camel.apache.org/camel-kamelets/[Kamelet catalog].

=== ConfigMap and Secret

You may also mount a configmap/secret to overwrite Kamelet properties with values from the configmap/secret resource.

Given a configmap named `my-log-sink-config` in Kubernetes that has two entries:

.my-log-sink-config
[source,properties]
----
showHeaders=true
level=DEBUG
----

You can reference the values of the configmap in the environment variables like this:

* CAMEL_KAMELET_LOG_SINK_SHOWHEADERS={{configmap:kn-sink-config/showHeaders}}
* CAMEL_KAMELET_LOG_SINK_LEVEL={{configmap:kn-sink-config/level}}

The configmap property values follow this general syntax:

[source,text]
----
configmap:name/key[:defaultValue]
----

This means you can also set a default value in case the configmap should not be present.

[source,text]
----
configmap:kn-sink-config/level:INFO
----

You can set the environment variables on the Kubernetes deployment for the connector:

[source,yaml]
----
apiVersion: apps/v1
kind: Deployment
metadata:
  name: log-sink
spec:
  selector:
    matchLabels:
      app.kubernetes.io/name: log-sink
      app.kubernetes.io/version: 1.0-SNAPSHOT
  template:
    spec:
      containers:
        - image: localhost:5001/openshift-knative/log-sink:1.0-SNAPSHOT
          imagePullPolicy: Always
          name: log-sink
          env:
            - name: CAMEL_KAMELET_LOG_SINK_SHOWHEADERS
              value: "{{configmap:kn-sink-config/showHeaders}}"
            - name: CAMEL_KAMELET_LOG_SINK_LEVEL
              value: "{{configmap:kn-sink-config/level:INFO}}"
----

In order to use the values from the configmap you need to add a volume and a volume mount to the deployment.

[source,yaml]
----
apiVersion: apps/v1
kind: Deployment
metadata:
  name: log-sink
spec:
  selector:
    matchLabels:
      app.kubernetes.io/name: log-sink
      app.kubernetes.io/version: 1.0-SNAPSHOT
  template:
    spec:
      containers:
        - image: localhost:5001/openshift-knative/log-sink:1.0-SNAPSHOT
          imagePullPolicy: Always
          name: log-sink
          env:
            - name: CAMEL_KAMELET_LOG_SINK_SHOWHEADERS
              value: "{{configmap:kn-sink-config/showHeaders}}"
            - name: CAMEL_KAMELET_LOG_SINK_LEVEL
              value: "{{configmap:kn-sink-config/level:INFO}}"
          volumeMounts:
            - mountPath: /etc/camel/conf.d/_configmaps/kn-sink-config
              name: log-sink-config
              readOnly: true
      volumes:
        - configMap:
            name: my-log-sink-config
          name: kn-sink-config
----

Camel is able to resolve the configmap mount path given in the volume mount.
The mount path is configurable via `application.properties` in the connector project:

* camel.kubernetes-config.mount-path-configmaps=/etc/camel/conf.d/_configmaps/kn-sink-config
* camel.kubernetes-config.mount-path-secrets=/etc/camel/conf.d/_secrets/kn-sink-config

The mount path configured on the Kubernetes deployment should match the configuration in the `application.properties`.

Instead of settings the mount paths statically in the `application.properties` you can also set these via environment variables on the
Kubernetes deployment.

* CAMEL_K_MOUNT_PATH_CONFIGMAPS=/etc/camel/conf.d/_configmaps/kn-sink-config
* CAMEL_K_MOUNT_PATH_SECRETS=/etc/camel/conf.d/_secrets/kn-sink-config

The same mechanism applies to mounting and configuring Kubernetes secrets.
The syntax for referencing a secret value in an environment variable is as follows:

[source,text]
----
secret:name/key[:defaultValue]
----

This means you can overwrite Kamelet properties with the values from the secret like this:

* CAMEL_KAMELET_LOG_SINK_SHOWHEADERS=secret:kn-sink-config/showHeaders
* CAMEL_KAMELET_LOG_SINK_LEVEL=secret:kn-sink-config/level

== CloudEvent attributes

Each connector sink consumes events in CloudEvent data format.
By default, the connector receives all events on the Knative broker.

You may want to specify filters on the CloudEvent attributes so that the connector selectively consumes events from the broker.
Just configure the Knative trigger to filter based on attributes:

.Knative trigger
[source,yaml]
----
apiVersion: eventing.knative.dev/v1
kind: Trigger
metadata:
  annotations:
    eventing.knative.dev/creator: kn-connectors
  labels:
    eventing.knative.dev/connector: log-sink
    eventing.knative.dev/broker: default
  name: kn-connector-log-sink
spec:
  broker: default
  filter:
    attributes:
      type: dev.knative.connector.event.timer
  subscriber:
    ref:
      apiVersion: v1
      kind: Service
      name: kn-connector-log-sink
    uri: /events
----

The trigger for example filters the events by its type `ce-type=dev.knative.connector.event.timer`.

== Dependencies

The required Camel dependencies need to be added to the Maven POM before building and deploying.
You can use one of the Kamelets available in the https://camel.apache.org/camel-kamelets/[Kamelet catalog] as a source or sink in this connector.

Typically, the Kamelet is backed by a Quarkus Camel extension component dependency that needs to be added to the Maven POM.
The Kamelets in use may list additional dependencies that we need to include in the Maven POM.

== More configuration options

For more information about Apache Camel Kamelets and their individual properties see https://camel.apache.org/camel-kamelets/.

For more detailed description of all container image configuration options please refer to the Quarkus Kubernetes extension and the container image guides:

* https://quarkus.io/guides/deploying-to-kubernetes
* https://quarkus.io/guides/container-image
